{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team members\n",
    "Username1ï¼š kl2912@columbia.edu,  Registered email address: kl2912@columbia.edu\n",
    "\n",
    "Username2:  zs2319 ,              Registered email address: zs2319@columbia.edu\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Describe your entity resolution technique, as well as its precision, recall, and F1 score.\n",
    "\n",
    "First, we did data processing and feature selection over the two data sets amazon.csv and rotten_tomatoes.csv. Since the same features that two data set shared were \"time\", \"director\" and \"star\", we decided to choose the three features to make up our classifier, thus dropped the unrelated columns like \"cost\" in amazon.csv, and audience rating and review relevant columns in rotten_tomatoes.csv.\n",
    "After that, we found out the two datasets did not have the same exact formatting for time and star. Therefore, we normalized the format of time features by using regular expression operations. In terms of the standardization of the star name features, we managed to build a set to contain all the star names appearing in each row to prepare for the \n",
    "intersection operation in the next step. \n",
    "After cleansing the two data sets, we created a data transformation function which basically would apply to train and test dataset. It added three new columns to the original data set, that are \"time_diff\", \"director_diff\" and \"star_diff\". \"time_diff\" was the absolute difference of the times, while \"director_diff\" was calculated by the string distance operation. Last but not least, \"director_diff\" was the length of intersection of two star name sets of id1 in amazon.csv and id2 in rotten_tomatoes.csv respectively.\n",
    "Then we applied the mean inputer and random forest classifier to fit our proccessed train data set to get our classifier. The precision, recall, and F1 score we got are all 1.0.\n",
    "At this point, the scores of train set was high enough, so we applied the classifier to predict the test dataset and got f1-score 96.25%.\n",
    "\n",
    "2. What were the most important features that powered your technique?\n",
    "There were three most importance features, which are \"time\", \"director\" and \"star\".\n",
    "\n",
    "3. How did you avoid pairwise comparison of all movies across both datasets?\n",
    "We created a data transformation function which basically would apply to train and test dataset. \n",
    "It added three new columns (\"time_diff\", \"director_diff\" and \"star_diff\") to the original data set, of which \"time_diff\" and \"director_diff\" stood for the absolute time difference and the normalized director string distance respectively between the row with id1 in amazon.csv and the row with id2 in rotten_tomatoes.csv, while \"star_diff\" represented the number of overlapped star names between the two rows.\n",
    "Through this step, we avoided pairwise comparison of all movies across both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re as re\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# read data\n",
    "\n",
    "amazon = pd.read_csv(\"amazon.csv\")\n",
    "\n",
    "rotten_tomatoes = pd.read_csv(\"rotten_tomatoes.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "holdout = pd.read_csv(\"holdout.csv\")\n",
    "\n",
    "rotten_selected = rotten_tomatoes.iloc[:, :10]\n",
    "\n",
    "## amazon data processing\n",
    "\n",
    "# deal with time period\n",
    "\n",
    "amazon = amazon.drop('cost', 1)\n",
    "\n",
    "for i in range(amazon.shape[0]):\n",
    "\n",
    "    starcol = str(amazon.loc[i]['star'])\n",
    "\n",
    "    if bool(re.search(r'\\d', starcol)):\n",
    "        amazon.set_value(i, 'time', starcol)\n",
    "\n",
    "        amazon.set_value(i, 'star', np.nan)  # cope with time column\n",
    "\n",
    "    timelong = str(amazon.loc[i]['time'])\n",
    "\n",
    "    if timelong.find('/') != -1:\n",
    "\n",
    "        amazon.set_value(i, 'time', np.nan)\n",
    "\n",
    "    else:\n",
    "\n",
    "        h = int(timelong.find('hour'))\n",
    "\n",
    "        mins = int(timelong.find('minute'))\n",
    "\n",
    "        comma = int(timelong.find(','))\n",
    "\n",
    "        if h != -1:\n",
    "\n",
    "            hours = int(timelong[h - 2])\n",
    "\n",
    "            minutes = int(timelong[comma + 2:mins - 1])\n",
    "\n",
    "        elif mins != -1:\n",
    "\n",
    "            hours = 0\n",
    "\n",
    "            minutes = int(timelong[:mins - 1])\n",
    "\n",
    "        else:\n",
    "\n",
    "            amazon.set_value(i, 'time', np.nan)\n",
    "\n",
    "        amazon.set_value(i, 'time', hours * 60 + minutes)\n",
    "\n",
    "# deal with star names\n",
    "\n",
    "for i in range(amazon.shape[0]):\n",
    "\n",
    "    # deal with star\n",
    "\n",
    "    starcol = str(amazon.loc[i]['star'])\n",
    "\n",
    "    if starcol.find('/') == -1:\n",
    "\n",
    "        starcol = set(starcol.split(', '))\n",
    "\n",
    "    else:\n",
    "\n",
    "        starcol = set(starcol.split('/'))\n",
    "\n",
    "    amazon.set_value(i, 'star', starcol)\n",
    "\n",
    "amazon_selected = amazon\n",
    "## rotten tomatoes data cleansing\n",
    "\n",
    "# deal with time\n",
    "\n",
    "prob = []\n",
    "\n",
    "for index, row in rotten_selected.iterrows():\n",
    "\n",
    "    timelong = row['time']\n",
    "\n",
    "    if str(timelong) != 'nan':\n",
    "\n",
    "        m = re.search(r'(\\d+) hr. (\\d+) min.', timelong)\n",
    "\n",
    "        m1 = re.search(r'(\\d+) hr.', timelong)\n",
    "\n",
    "        m2 = re.search(r'(\\d+) min.', timelong)\n",
    "\n",
    "        if m:\n",
    "\n",
    "            time_tup = m.groups()\n",
    "\n",
    "            minute = int(time_tup[0]) * 60 + int(time_tup[1])\n",
    "\n",
    "        elif m1:\n",
    "\n",
    "            time_tup = m1.groups()\n",
    "\n",
    "            minute = int(time_tup[0]) * 60\n",
    "\n",
    "        elif m2:\n",
    "\n",
    "            time_tup = m2.groups()\n",
    "\n",
    "            minute = int(time_tup[0])\n",
    "\n",
    "        else:\n",
    "\n",
    "            prob.append(index)\n",
    "\n",
    "        rotten_selected.set_value(index, 'time', minute)\n",
    "\n",
    "rotten_selected = rotten_selected.drop('year', 1)\n",
    "\n",
    "# combine star1 to star6 into a column of sets star\n",
    "\n",
    "rotten_selected['star'] = [set() for x in range(len(rotten_selected.index))]\n",
    "\n",
    "for index, row in rotten_selected.iterrows():\n",
    "\n",
    "    star = set()\n",
    "\n",
    "    for i in range(3, 9):\n",
    "\n",
    "        if str(row[i]) != 'nan':\n",
    "            star.add(row[i])\n",
    "\n",
    "    rotten_selected.set_value(index, 'star', star)\n",
    "\n",
    "rotten_selected = rotten_selected.iloc[:, [0, 1, 2, 9]]\n",
    "\n",
    "# transform training set\n",
    "\n",
    "import distance\n",
    "\n",
    "\n",
    "def transformation(X):\n",
    "    \"\"\"\n",
    "\n",
    "    transform train into standard format\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    X['time_diff'] = 0\n",
    "\n",
    "    X['director_diff'] = 0\n",
    "\n",
    "    X['star_diff'] = 0\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        id_amazon = X.iloc[i, 0]\n",
    "\n",
    "        id_rotten = X.iloc[i, 1]\n",
    "\n",
    "        row_amazon = amazon_selected[amazon_selected['id'] == id_amazon]\n",
    "\n",
    "        row_rotten = rotten_selected[rotten_selected['id'] == id_rotten]\n",
    "\n",
    "        X.iloc[i, 3] = np.absolute(float(row_amazon['time']) - float(row_rotten['time']))\n",
    "\n",
    "        X.iloc[i, 4] = distance.levenshtein(str(row_amazon['director']), str(row_rotten['director']), normalized=True)\n",
    "\n",
    "        # the intersection of star names\n",
    "\n",
    "        amazon_star = list(row_amazon['star'])[0]\n",
    "\n",
    "        rotten_star = list(row_rotten['star'])[0]\n",
    "\n",
    "        X.iloc[i, 5] = len(amazon_star.intersection(rotten_star))\n",
    "\n",
    "    X_train = X.iloc[:, [0, 1, 3, 4, 5]]\n",
    "\n",
    "    y_train = X.iloc[:, 2]\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "X_train,y_train=transformation(train)\n",
    "\n",
    "test['gold'] = 0\n",
    "X_test, y_test = transformation(test)\n",
    "holdout['gold'] = 0\n",
    "X_holdout, y_holdout = transformation(holdout)\n",
    "\n",
    "\n",
    "imp = Imputer(strategy=\"mean\").fit(X_train)\n",
    "X_train_imp = imp.transform(X_train)\n",
    "X_test_imp = imp.transform(X_test)\n",
    "X_holdout_imp = imp.transform(X_holdout)\n",
    "\n",
    "# rf = RandomForestClassifier(n_estimators=15)\n",
    "# rf.fit(X_train_imp[:,2:5],y_train)\n",
    "# rf.score(X_train_imp[:,2:5], y_train)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#rf = AdaBoostClassifier(base_estimator=RandomForestClassifier, n_estimators=20)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "rf.fit(X_train_imp[:,2:5],y_train)\n",
    "\n",
    "rf.score(X_train_imp[:,2:5], y_train)\n",
    "\n",
    "pred = rf.predict(X_test_imp[:,2:5])\n",
    "\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "\n",
    "train_pred=rf.predict(X_train_imp[:,2:5])\n",
    "\n",
    "print(rf.score(X_train_imp[:,2:5], y_train))\n",
    "\n",
    "print(f1_score(y_train,train_pred,average=\"macro\"))\n",
    "\n",
    "print(precision_score(y_train,train_pred,average=\"macro\"))\n",
    "\n",
    "print(recall_score(y_train,train_pred,average=\"macro\"))\n",
    "\n",
    "prediction = pd.DataFrame(pred,columns=['gold'])\n",
    "\n",
    "prediction = prediction.to_csv('gold.csv',index=False)\n",
    "\n",
    "prediction2 = pd.DataFrame(rf.predict(X_holdout_imp[:, 2:5]), columns=['gold'])\n",
    "\n",
    "prediction2 = prediction2.to_csv('gold2.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
